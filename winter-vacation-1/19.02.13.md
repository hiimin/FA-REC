# 19.02.13

## todo

* 눈감김 감지
* 졸음 알림

## how

{% embed url="https://www.youtube.com/watch?v=dJjzTo8\_x3c" %}

위 동영상의 코드를 참조

딥러닝 학습을 통한 눈 깜빡임 인식후 1초이상 눈을 감고 있었을 경우 졸음이라고 판단

`cap = cv2.VideoCapture('동영상파일 경로')` 파일 경로에 0을 매개변수로 주어 내장 카메라를 입력으로 받음

## trouble

* `import cv2` 할 경우 opencv-python, opencv-contrib-python 두 모듈을 install 해주어야 됨
* `ImportError: numpy.core._multiarray_umath failed to import numpy` 오류 발생시 설치되어 있는 numpy 모듈을 삭제후 최신버젼의 numpy 모듈을 새로 install 함으로 해결

## code

```text
import cv2, dlib
import numpy as np
from imutils import face_utils
from keras.models import load_model
import time

IMG_SIZE = (34, 26)

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

model = load_model('models/2018_12_17_22_58_35.h5')
model.summary()

def crop_eye(img, eye_points):
  x1, y1 = np.amin(eye_points, axis=0)
  x2, y2 = np.amax(eye_points, axis=0)
  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2

  w = (x2 - x1) * 1.2
  h = w * IMG_SIZE[1] / IMG_SIZE[0]

  margin_x, margin_y = w / 2, h / 2

  min_x, min_y = int(cx - margin_x), int(cy - margin_y)
  max_x, max_y = int(cx + margin_x), int(cy + margin_y)

  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)

  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]

  return eye_img, eye_rect

# main
#cap = cv2.VideoCapture('videos/1.mp4')
cap = cv2.VideoCapture(0) #내장 카메라 입력

lclose = 0
rclose = 0
closetime = 0
closeStart = 0
closeEnd = 0

while cap.isOpened():
  ret, img_ori = cap.read()

  if not ret:
    break

  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)

  img = img_ori.copy()
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  faces = detector(gray)

  for face in faces:
    shapes = predictor(gray, face)
    shapes = face_utils.shape_to_np(shapes)

    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])
    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])

    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)
    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)
    eye_img_r = cv2.flip(eye_img_r, flipCode=1)

    cv2.imshow('l', eye_img_l)
    cv2.imshow('r', eye_img_r)

    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.
    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.

    pred_l = model.predict(eye_input_l)
    pred_r = model.predict(eye_input_r)

    # visualize
    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'
    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'

    state_l = state_l % pred_l
    state_r = state_r % pred_r

    lB = 0
    rB = 0
    lG = 0
    rG = 0
    lR = 0
    rR = 0

    if pred_l < 0.1:
        lR = 255
        lB = 0
        lG = 0
        lclose = 1
    else:
        lB = 255
        lR = 0
        lG = 0
        lclose = 0
        closetime = 0;

    if pred_r < 0.1:
        rR = 255
        rB = 0
        rG = 0
        rclose = 1
    else:
        rB = 255
        rR = 0
        rG = 0
        rclose = 0
        closetime = 0

    if rclose == 1 and lclose == 1 and closeStart == 0:
        closeStart = time.time()
    elif rclose == 1 and lclose == 1:
        closetime = time.time() - closeStart
    else:
        closeStart = 0

    if rclose == 1 and lclose == 1 and closetime > 1:   #1초 이상 눈을 감았을 경우
        lR = lG = lB = rR = rG = rB = 256

    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(lB,lG,lR), thickness=2)
    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(rB,rG,rR), thickness=2)

    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (lB,lG,lR), 2)
    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (rB,rG,rR), 2)

  cv2.imshow('result', img)
  if cv2.waitKey(1) == ord('q'):
    break

```

